# internship-project-1
End-to-end data pipeline using Apache Spark (Scala) to read, clean, and store CSV data in Parquet format on HDFS, create temporary views, and integrate with Hive for querying and analytics.
